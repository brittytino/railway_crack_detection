{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Railway Crack Detection - Model Training\n",
        "\n",
        "Train and evaluate machine learning models for crack detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "sys.path.append('../')\n",
        "\n",
        "from src.models.classifier import RailwayDefectClassifier\n",
        "from src.models.ensemble import EnsembleClassifier\n",
        "from src.evaluation.metrics import ModelEvaluator\n",
        "from src.augmentation.diffusion_generator import DiffusionAudioGenerator\n",
        "from src.utils.visualization import plot_confusion_matrix\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print('\u2705 Imports successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Processed Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load features and labels\n",
        "data_dir = Path('../data/processed')\n",
        "\n",
        "X = np.load(data_dir / 'features.npy')\n",
        "y = np.load(data_dir / 'labels.npy')\n",
        "\n",
        "# Load feature names\n",
        "with open(data_dir / 'feature_names.txt', 'r') as f:\n",
        "    feature_names = f.read().splitlines()\n",
        "\n",
        "print(f'Features shape: {X.shape}')\n",
        "print(f'Labels shape: {y.shape}')\n",
        "print(f'Number of features: {len(feature_names)}')\n",
        "print(f'\\nClass distribution:')\n",
        "print(f'  Healthy (0): {np.sum(y==0)}')\n",
        "print(f'  Defective (1): {np.sum(y==1)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "print(f'Training samples: {len(X_train)}')\n",
        "print(f'Test samples: {len(X_test)}')\n",
        "print(f'\\nTraining class distribution:')\n",
        "print(f'  Healthy: {np.sum(y_train==0)}')\n",
        "print(f'  Defective: {np.sum(y_train==1)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train Random Forest\n",
        "print('Training Random Forest...')\n",
        "rf_classifier = RailwayDefectClassifier(\n",
        "    model_type='random_forest',\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "rf_classifier.train(X_train, y_train)\n",
        "print('\u2705 Training complete')\n",
        "\n",
        "# Evaluate\n",
        "rf_metrics = rf_classifier.evaluate(X_test, y_test)\n",
        "print('\\nRandom Forest Performance:')\n",
        "print(f\"  Accuracy:  {rf_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {rf_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {rf_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {rf_metrics['f1_score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train XGBoost\n",
        "print('Training XGBoost...')\n",
        "xgb_classifier = RailwayDefectClassifier(\n",
        "    model_type='xgboost',\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "xgb_classifier.train(X_train, y_train)\n",
        "print('\u2705 Training complete')\n",
        "\n",
        "# Evaluate\n",
        "xgb_metrics = xgb_classifier.evaluate(X_test, y_test)\n",
        "print('\\nXGBoost Performance:')\n",
        "print(f\"  Accuracy:  {xgb_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {xgb_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {xgb_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {xgb_metrics['f1_score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train SVM\n",
        "print('Training SVM...')\n",
        "svm_classifier = RailwayDefectClassifier(\n",
        "    model_type='svm',\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "svm_classifier.train(X_train, y_train)\n",
        "print('\u2705 Training complete')\n",
        "\n",
        "# Evaluate\n",
        "svm_metrics = svm_classifier.evaluate(X_test, y_test)\n",
        "print('\\nSVM Performance:')\n",
        "print(f\"  Accuracy:  {svm_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {svm_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {svm_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {svm_metrics['f1_score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train Ensemble\n",
        "print('Training Ensemble Model...')\n",
        "ensemble = EnsembleClassifier()\n",
        "ensemble.train(X_train, y_train)\n",
        "print('\u2705 Ensemble training complete')\n",
        "\n",
        "# Evaluate\n",
        "ensemble_metrics = ensemble.evaluate(X_test, y_test)\n",
        "print('\\nEnsemble Performance:')\n",
        "print(f\"  Accuracy:  {ensemble_metrics['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {ensemble_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {ensemble_metrics['recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {ensemble_metrics['f1_score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'XGBoost', 'SVM', 'Ensemble'],\n",
        "    'Accuracy': [\n",
        "        rf_metrics['accuracy'],\n",
        "        xgb_metrics['accuracy'],\n",
        "        svm_metrics['accuracy'],\n",
        "        ensemble_metrics['accuracy']\n",
        "    ],\n",
        "    'Precision': [\n",
        "        rf_metrics['precision'],\n",
        "        xgb_metrics['precision'],\n",
        "        svm_metrics['precision'],\n",
        "        ensemble_metrics['precision']\n",
        "    ],\n",
        "    'Recall': [\n",
        "        rf_metrics['recall'],\n",
        "        xgb_metrics['recall'],\n",
        "        svm_metrics['recall'],\n",
        "        ensemble_metrics['recall']\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        rf_metrics['f1_score'],\n",
        "        xgb_metrics['f1_score'],\n",
        "        svm_metrics['f1_score'],\n",
        "        ensemble_metrics['f1_score']\n",
        "    ]\n",
        "})\n",
        "\n",
        "print('\\nModel Comparison:')\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Plot comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "comparison_df.set_index('Model').plot(kind='bar', ax=ax, rot=0)\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.set_ylim([0, 1.0])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get ensemble predictions\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot\n",
        "fig = plot_confusion_matrix(\n",
        "    cm,\n",
        "    class_labels=['Healthy', 'Defective'],\n",
        "    title='Ensemble Model - Confusion Matrix'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print('\\nDetailed Classification Report:')\n",
        "print(classification_report(y_test, y_pred, target_names=['Healthy', 'Defective']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance from Random Forest\n",
        "importance = rf_classifier.get_feature_importance()\n",
        "\n",
        "if importance is not None:\n",
        "    # Get top 20 features\n",
        "    top_n = 20\n",
        "    indices = np.argsort(importance)[::-1][:top_n]\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.barh(range(top_n), importance[indices])\n",
        "    ax.set_yticks(range(top_n))\n",
        "    ax.set_yticklabels([feature_names[i] for i in indices])\n",
        "    ax.set_xlabel('Importance')\n",
        "    ax.set_title(f'Top {top_n} Most Important Features', fontsize=14, fontweight='bold')\n",
        "    ax.invert_yaxis()\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ensemble model (best performer)\n",
        "model_dir = Path('../models/trained')\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save individual classifiers\n",
        "rf_classifier.save(model_dir / 'random_forest_model.pkl')\n",
        "xgb_classifier.save(model_dir / 'xgboost_model.pkl')\n",
        "svm_classifier.save(model_dir / 'svm_model.pkl')\n",
        "\n",
        "print('\u2705 Models saved successfully!')\n",
        "print(f'   - Random Forest: {model_dir / \"random_forest_model.pkl\"}')\n",
        "print(f'   - XGBoost: {model_dir / \"xgboost_model.pkl\"}')\n",
        "print(f'   - SVM: {model_dir / \"svm_model.pkl\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook:\n",
        "- Trained multiple classifiers (RF, XGBoost, SVM, Ensemble)\n",
        "- Evaluated model performance\n",
        "- Compared different approaches\n",
        "- Analyzed feature importance\n",
        "- Saved trained models\n",
        "\n",
        "**Best Model:** Ensemble (combining RF + XGBoost + SVM)\n",
        "\n",
        "**Next Steps:**\n",
        "- Deploy model in Streamlit app\n",
        "- Test with real railway acoustic data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}