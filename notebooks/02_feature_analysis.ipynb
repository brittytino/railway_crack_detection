{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Railway Crack Detection - Feature Analysis\n",
        "\n",
        "Extract and analyze acoustic features for crack detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.append('../')\n",
        "\n",
        "from src.preprocessing.audio_loader import AudioLoader\n",
        "from src.preprocessing.noise_filter import NoiseFilter\n",
        "from src.feature_extraction.mfcc_extractor import MFCCExtractor\n",
        "from src.feature_extraction.spectral_features import SpectralFeatureExtractor\n",
        "from src.feature_extraction.fractal_analysis import FractalAnalyzer\n",
        "from src.utils.audio_utils import load_audio_files_from_directory\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print('\u2705 Imports successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "HEALTHY_DIR = '../data/raw/healthy'\n",
        "DEFECTIVE_DIR = '../data/raw/defective'\n",
        "SAMPLE_RATE = 22050\n",
        "N_MFCC = 20\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "\n",
        "# Load audio\n",
        "healthy_audio, _ = load_audio_files_from_directory(HEALTHY_DIR, SAMPLE_RATE)\n",
        "defective_audio, _ = load_audio_files_from_directory(DEFECTIVE_DIR, SAMPLE_RATE)\n",
        "\n",
        "print(f'Loaded {len(healthy_audio)} healthy and {len(defective_audio)} defective samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize preprocessor\n",
        "noise_filter = NoiseFilter(sample_rate=SAMPLE_RATE)\n",
        "\n",
        "# Preprocess all samples\n",
        "print('Preprocessing audio...')\n",
        "healthy_clean = [noise_filter.preprocess(audio) for audio in tqdm(healthy_audio)]\n",
        "defective_clean = [noise_filter.preprocess(audio) for audio in tqdm(defective_audio)]\n",
        "\n",
        "print('\u2705 Preprocessing complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize extractors\n",
        "mfcc_extractor = MFCCExtractor(SAMPLE_RATE, N_MFCC, N_FFT, HOP_LENGTH)\n",
        "spectral_extractor = SpectralFeatureExtractor(SAMPLE_RATE, N_FFT, HOP_LENGTH)\n",
        "fractal_analyzer = FractalAnalyzer(SAMPLE_RATE)\n",
        "\n",
        "def extract_features(audio_list, label):\n",
        "    \"\"\"Extract all features from audio list\"\"\"\n",
        "    features_list = []\n",
        "    \n",
        "    for audio in tqdm(audio_list, desc=f'Extracting {label} features'):\n",
        "        # MFCC\n",
        "        mfcc_feat = mfcc_extractor.extract_full_features(audio)\n",
        "        \n",
        "        # Spectral\n",
        "        spectral_feat = spectral_extractor.extract_all_features(audio)\n",
        "        \n",
        "        # Fractal\n",
        "        fractal_feat = fractal_analyzer.extract_all_fractal_features(audio)\n",
        "        \n",
        "        # Combine\n",
        "        all_features = np.concatenate([mfcc_feat, spectral_feat, fractal_feat])\n",
        "        features_list.append(all_features)\n",
        "    \n",
        "    return np.array(features_list)\n",
        "\n",
        "# Extract features\n",
        "print('Extracting features...')\n",
        "healthy_features = extract_features(healthy_clean, 'Healthy')\n",
        "defective_features = extract_features(defective_clean, 'Defective')\n",
        "\n",
        "print(f'\\nFeature shape: {healthy_features.shape}')\n",
        "print(f'Total features per sample: {healthy_features.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create feature DataFrame\n",
        "n_mfcc_features = 120  # 20 MFCCs * 6 statistics\n",
        "n_spectral_features = 13\n",
        "n_fractal_features = 4\n",
        "\n",
        "feature_names = (\n",
        "    [f'MFCC_{i}' for i in range(n_mfcc_features)] +\n",
        "    [f'Spectral_{i}' for i in range(n_spectral_features)] +\n",
        "    ['Higuchi_FD', 'Petrosian_FD', 'Katz_FD', 'Hurst_Exp']\n",
        ")\n",
        "\n",
        "# Combine all features\n",
        "all_features = np.vstack([healthy_features, defective_features])\n",
        "labels = np.array([0]*len(healthy_features) + [1]*len(defective_features))\n",
        "\n",
        "# Create DataFrame\n",
        "df_features = pd.DataFrame(all_features, columns=feature_names)\n",
        "df_features['label'] = labels\n",
        "df_features['label_name'] = df_features['label'].map({0: 'Healthy', 1: 'Defective'})\n",
        "\n",
        "print('Feature statistics:')\n",
        "print(df_features.groupby('label_name').describe().T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature distributions for key features\n",
        "key_features = ['MFCC_0', 'MFCC_20', 'Spectral_0', 'Higuchi_FD', 'Hurst_Exp']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    if feature in df_features.columns:\n",
        "        df_features[df_features['label']==0][feature].hist(\n",
        "            ax=axes[i], bins=30, alpha=0.6, label='Healthy', color='green'\n",
        "        )\n",
        "        df_features[df_features['label']==1][feature].hist(\n",
        "            ax=axes[i], bins=30, alpha=0.6, label='Defective', color='red'\n",
        "        )\n",
        "        axes[i].set_xlabel(feature)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].legend()\n",
        "        axes[i].grid(alpha=0.3)\n",
        "\n",
        "# Remove extra subplot\n",
        "fig.delaxes(axes[-1])\n",
        "\n",
        "plt.suptitle('Feature Distributions: Healthy vs Defective', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate correlation matrix for key features\n",
        "key_features_with_label = key_features + ['label']\n",
        "corr_matrix = df_features[key_features_with_label].corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "            center=0, square=True, ax=ax, cbar_kws={'label': 'Correlation'})\n",
        "ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Processed Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save features to processed directory\n",
        "output_dir = Path('../data/processed')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save as numpy arrays\n",
        "np.save(output_dir / 'features.npy', all_features)\n",
        "np.save(output_dir / 'labels.npy', labels)\n",
        "\n",
        "# Save feature names\n",
        "with open(output_dir / 'feature_names.txt', 'w') as f:\n",
        "    f.write('\\n'.join(feature_names))\n",
        "\n",
        "print(f'\u2705 Features saved to {output_dir}')\n",
        "print(f'   - features.npy: {all_features.shape}')\n",
        "print(f'   - labels.npy: {labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook:\n",
        "- Preprocessed audio with noise filtering\n",
        "- Extracted MFCC, spectral, and fractal features\n",
        "- Analyzed feature distributions and correlations\n",
        "- Saved processed features for model training\n",
        "\n",
        "**Next:** Model training (Notebook 03)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}